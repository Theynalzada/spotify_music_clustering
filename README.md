# Data Science Project: Spotify Music Clustering
![](https://i.imgur.com/tpiJp0A.jpg)

## Project Description & Data Collection
The goal of the project is to successfully cluster tracks in Spotify based on their audio features. In order to scrape the audio features I have used a Python library called **spotipy**. I created a crawler that automatically extracts the audio features based on the provided singers and tracks in the configuration file while writing the output to a separate logger file. The dataset contains **1019** tracks of various music genres from **25** different singers.

## Modeling
The dataset contains **9** independent features which are following.

1. **danceability** - It is a music/audio feature that describes how suitable a piece of music is for dancing. It is a measure of the rhythm, tempo, and beat of a song, and is often quantified using numerical values that reflect these qualities. The danceability feature is typically computed by analyzing various components of the music, such as the tempo, rhythm, and beat, and then combining these factors into a single score that indicates how easy or difficult it is to dance to the music. Other factors that may be taken into account include the presence of a strong, consistent beat, the use of percussion instruments, and the overall energy and excitement of the music.Danceability is often used as a key feature in music recommendation systems, and it can also be used to help DJs create playlists that are optimized for dancing. Many popular streaming services, such as Spotify and Apple Music, use danceability as one of the metrics to recommend music to users based on their preferences.
2. **energy** - It is an audio feature that describes the perceived intensity and activity level of a piece of music. It is a measure of the overall sound level and dynamics of a song, and is often quantified using numerical values that reflect these qualities. The energy of a song is typically determined by analyzing various components of the music, such as the loudness, pitch, and timbre, and then combining these factors into a single score that indicates how intense or active the music sounds. Other factors that may be taken into account include the use of instruments, the tempo, and the overall complexity of the music. In music production, energy is an important consideration, as it can affect the emotional impact of a song and its suitability for different contexts. For example, high-energy music is often used in sports or workout videos to create a sense of motivation and excitement, while lower-energy music may be more suitable for relaxation or background music.
3. **loudness** - It is an audio feature that describes the perceived volume of a piece of sound or music. It is a measure of the amplitude of the sound waves and how it is perceived by the human ear. Loudness can be quantified using various numerical scales, such as decibels (dB). The loudness of a sound or music is determined by various factors, such as the amplitude, frequency, and duration of the sound waves. It can be affected by the recording and mixing process, as well as the playback equipment and environment. In music production, loudness is an important consideration, as it can affect the overall impact of a song and its perceived quality. For example, some genres of music, such as rock or metal, may require a higher degree of loudness to create a sense of intensity and power, while others, such as classical music or jazz, may require a more balanced and nuanced approach to loudness. It's worth noting that while loudness and volume are often used interchangeably, they are not the same thing. Volume refers to the physical quantity of sound waves, while loudness refers to the perception of volume by the human ear.
4. **speechiness** - It is an audio feature that describes the extent to which a piece of audio consists of spoken words or vocalization, as opposed to music or other non-speech sounds. It is a measure of the presence and prominence of human speech in a recording and can be quantified using numerical values. The speechiness of a recording is determined by analyzing various acoustic features of the audio signal, such as the frequency range, rhythmic patterns, and vocal characteristics. For example, speech tends to have a more narrow frequency range than music, and it often exhibits distinct patterns of pitch and timing. Speechiness is a useful feature for various applications, such as speech recognition and audio classification. For example, speech recognition systems may use speechiness to distinguish between spoken commands and other types of audio input. In music recommendation systems, speechiness can be used to identify spoken-word recordings or other types of audio content that are predominantly speech-based, such as podcasts or audiobooks.
5. **acousticness** - It is an audio feature that describes the degree to which a piece of music relies on acoustic instruments or sounds, as opposed to electronic or digital sounds. It is a measure of the sound texture of a recording and can be quantified using numerical values. The acousticness of a recording is determined by analyzing various acoustic features of the audio signal, such as the presence and prominence of acoustic instruments, the reverberation and resonance of the recording space, and the overall tonal balance of the sound. For example, acoustic instruments such as guitars, pianos, and drums tend to produce more natural and organic sounds than electronic or digital instruments. Acousticness is often used as a feature in music recommendation systems, as it can help to identify recordings that have a more natural and organic sound. It can also be used in music production to create a particular sound aesthetic or to enhance the authenticity of a recording. For example, acousticness may be emphasized in certain genres of music, such as folk or country, where acoustic instruments are a defining characteristic of the sound.
6. **instrumentalness** - It is an audio feature that describes the degree to which a piece of music contains vocals or singing, as opposed to being purely instrumental. It is a measure of the presence and prominence of vocals in a recording and can be quantified using numerical values. The instrumentalness of a recording is determined by analyzing various acoustic features of the audio signal, such as the presence and prominence of vocal elements, the lyrics content, and the rhythmic patterns of the music. For example, instrumental music will have no vocals or singing, whereas music that contains vocals will have varying degrees of instrumental and vocal elements. Instrumentalness is often used as a feature in music recommendation systems and music streaming services, as it can help to identify and classify music based on the presence or absence of vocals. It can also be used in music production to create a particular sound aesthetic or to enhance the artistic direction of a recording. For example, instrumentalness may be emphasized in certain genres of music, such as classical or jazz, where instrumental elements are a defining characteristic of the sound.
7. **liveness** - It is an audio feature that describes the degree to which a piece of music sounds like a live performance or a studio recording. It is a measure of the sound environment in which the recording was made and can be quantified using numerical values. The liveness of a recording is determined by analyzing various acoustic features of the audio signal, such as the presence and prominence of audience sounds, the ambient acoustics of the recording space, and the overall tonal balance of the sound. Live recordings tend to have more ambient and background sounds, as well as more variations in the sound quality, compared to studio recordings which tend to have a more consistent and polished sound. Liveness can be an important consideration in music production, as it can affect the emotional impact and perceived authenticity of a recording. For example, some genres of music, such as rock or jazz, may benefit from a higher degree of liveness to capture the energy and spontaneity of a live performance. In contrast, other genres of music, such as electronic or pop music, may require a more controlled and polished sound that is typically associated with studio recordings.
8. **valence** - It is an audio feature that describes the positive or negative emotional character of a piece of music. It is a measure of the overall mood or affective tone of a recording and can be quantified using numerical values. The valence of a recording is determined by analyzing various acoustic features of the audio signal, such as the tempo, tonality, and timbre of the music. For example, music that is characterized by a fast tempo, major tonality, and bright timbres tends to have a more positive or uplifting emotional character, while music that is characterized by a slow tempo, minor tonality, and darker timbres tends to have a more negative or melancholic emotional character. Valence can be an important consideration in music recommendation systems and music streaming services, as it can help to classify music based on the emotional character of the recording. It can also be used in music production to create a particular emotional response or to enhance the artistic direction of a recording. For example, a composer or producer may aim to create music with a specific valence to convey a particular emotion or to fit the mood of a particular scene or context.
9. **tempo** - It is an audio feature that describes the speed or pace of a piece of music, typically measured in beats per minute (BPM). It is a measure of the rhythmic structure of a recording and can be quantified using numerical values. The tempo of a recording is determined by analyzing various acoustic features of the audio signal, such as the time between beats, the presence of accentuated beats, and the overall rhythmic patterns of the music. For example, music that is characterized by a fast and consistent beat will have a higher tempo than music that is characterized by a slow and irregular beat. Tempo can be an important consideration in music production, as it can affect the emotional impact and perceived energy of a recording. For example, music with a fast tempo is often associated with excitement and energy, while music with a slower tempo is often associated with relaxation and introspection. Tempo can also be used to categorize or classify music into different genres or sub-genres, such as dance music, which typically has a faster tempo than other genres like ballads or slow jazz.

Since it is a clustering problem I used a flat clustering algorithm **KMeans** and in order to define the number of clusters I used **Elbow** method and I chose **3** as the final number of clusters. 

![](https://i.imgur.com/r9uVrXF.png)

Based on the aggregated data of each cluster, I labeled clusters such as **Energetic**, **Balanced** and **Acoustic**.

![](https://i.imgur.com/Eo3iOU3.png)